{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0_LinearClassification_BreastCancer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGQAPg4EBlOjmEh7py/ggN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravishankarramakrishnan/Deep_Learning_Practice/blob/master/0_LinearClassification_BreastCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91YtNADj_mwf",
        "colab_type": "code",
        "outputId": "1c8ae4b8-393e-41b2-e6dc-80511cc68731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install -q tensorflow==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 87.9MB 63kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 46.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 52.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsM_CDCy_7fV",
        "colab_type": "code",
        "outputId": "2b285cf1-5cdf-4c69-b469-c1e9433d9073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# importing the Libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psyVyqn-AE9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Data\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqCaTlHjAUHi",
        "colab_type": "code",
        "outputId": "03f12f43-78ed-42a0-d7b3-da90e242a566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check type of data\n",
        "type(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byaQSd18AaeS",
        "colab_type": "code",
        "outputId": "3d7fd031-9ee5-486a-d476-3d64e78f45b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Bunck is like Dictionary\n",
        "data.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgsVhrsuAeAq",
        "colab_type": "code",
        "outputId": "2da120dd-9c31-4f39-a97e-6579e9694e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check the Shape of the Dataset\n",
        "data.data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXoe70YKAoZo",
        "colab_type": "code",
        "outputId": "ec95ae00-cefc-427c-dc27-f996ae02440a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# Check the Target Column\n",
        "data.target"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NslHJOWYAuAx",
        "colab_type": "code",
        "outputId": "408f62e6-707b-4dce-c9c1-2b514f102bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check their Names\n",
        "data.target_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7TqepLpAz0h",
        "colab_type": "code",
        "outputId": "b9807092-3706-4e5e-eb21-c1890c7928fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Check Feature Names\n",
        "data.feature_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQll6TsLA4Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Building\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZNpmcWnBQPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the Numbers and Dimensions for Entering into Deep Learning Input Layer Size\n",
        "N,D = X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9k0nPfEBZIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the Data for even distribution of Range across Features\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FNRo54iB5d4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the Model\n",
        "'''\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Input(shape = (D,)),\n",
        "                                    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "'''\n",
        "\n",
        "# As We get Model Load Error, we follow the below\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1, input_shape = (D,), activation=\"sigmoid\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOmW8UBFCWkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the Model\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAXrxWwyCmpK",
        "colab_type": "code",
        "outputId": "52be75f5-5098-48c3-ab50-91b055d40ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)\n",
        "\n",
        "print(\"Train Score:\", model.evaluate(X_train, y_train))\n",
        "print(\"Test Score:\", model.evaluate(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 381 samples, validate on 188 samples\n",
            "Epoch 1/100\n",
            "381/381 [==============================] - 0s 451us/sample - loss: 0.5890 - accuracy: 0.7218 - val_loss: 0.5564 - val_accuracy: 0.7340\n",
            "Epoch 2/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.5367 - accuracy: 0.7900 - val_loss: 0.5118 - val_accuracy: 0.7926\n",
            "Epoch 3/100\n",
            "381/381 [==============================] - 0s 64us/sample - loss: 0.4929 - accuracy: 0.8058 - val_loss: 0.4743 - val_accuracy: 0.8298\n",
            "Epoch 4/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.4564 - accuracy: 0.8268 - val_loss: 0.4428 - val_accuracy: 0.8351\n",
            "Epoch 5/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.4251 - accuracy: 0.8583 - val_loss: 0.4164 - val_accuracy: 0.8511\n",
            "Epoch 6/100\n",
            "381/381 [==============================] - 0s 55us/sample - loss: 0.3992 - accuracy: 0.8924 - val_loss: 0.3931 - val_accuracy: 0.8883\n",
            "Epoch 7/100\n",
            "381/381 [==============================] - 0s 55us/sample - loss: 0.3763 - accuracy: 0.8976 - val_loss: 0.3732 - val_accuracy: 0.8883\n",
            "Epoch 8/100\n",
            "381/381 [==============================] - 0s 74us/sample - loss: 0.3562 - accuracy: 0.9081 - val_loss: 0.3556 - val_accuracy: 0.9043\n",
            "Epoch 9/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.3388 - accuracy: 0.9081 - val_loss: 0.3397 - val_accuracy: 0.9043\n",
            "Epoch 10/100\n",
            "381/381 [==============================] - 0s 57us/sample - loss: 0.3229 - accuracy: 0.9134 - val_loss: 0.3256 - val_accuracy: 0.9096\n",
            "Epoch 11/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.3089 - accuracy: 0.9134 - val_loss: 0.3125 - val_accuracy: 0.9043\n",
            "Epoch 12/100\n",
            "381/381 [==============================] - 0s 62us/sample - loss: 0.2960 - accuracy: 0.9160 - val_loss: 0.3007 - val_accuracy: 0.9096\n",
            "Epoch 13/100\n",
            "381/381 [==============================] - 0s 87us/sample - loss: 0.2845 - accuracy: 0.9186 - val_loss: 0.2898 - val_accuracy: 0.9149\n",
            "Epoch 14/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.2735 - accuracy: 0.9186 - val_loss: 0.2802 - val_accuracy: 0.9149\n",
            "Epoch 15/100\n",
            "381/381 [==============================] - 0s 55us/sample - loss: 0.2641 - accuracy: 0.9213 - val_loss: 0.2710 - val_accuracy: 0.9202\n",
            "Epoch 16/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.2550 - accuracy: 0.9239 - val_loss: 0.2624 - val_accuracy: 0.9202\n",
            "Epoch 17/100\n",
            "381/381 [==============================] - 0s 64us/sample - loss: 0.2468 - accuracy: 0.9318 - val_loss: 0.2543 - val_accuracy: 0.9202\n",
            "Epoch 18/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.2390 - accuracy: 0.9370 - val_loss: 0.2470 - val_accuracy: 0.9255\n",
            "Epoch 19/100\n",
            "381/381 [==============================] - 0s 68us/sample - loss: 0.2316 - accuracy: 0.9423 - val_loss: 0.2402 - val_accuracy: 0.9255\n",
            "Epoch 20/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.2251 - accuracy: 0.9475 - val_loss: 0.2336 - val_accuracy: 0.9309\n",
            "Epoch 21/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.2188 - accuracy: 0.9475 - val_loss: 0.2274 - val_accuracy: 0.9362\n",
            "Epoch 22/100\n",
            "381/381 [==============================] - 0s 65us/sample - loss: 0.2129 - accuracy: 0.9449 - val_loss: 0.2216 - val_accuracy: 0.9468\n",
            "Epoch 23/100\n",
            "381/381 [==============================] - 0s 64us/sample - loss: 0.2073 - accuracy: 0.9475 - val_loss: 0.2161 - val_accuracy: 0.9468\n",
            "Epoch 24/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.2024 - accuracy: 0.9475 - val_loss: 0.2107 - val_accuracy: 0.9468\n",
            "Epoch 25/100\n",
            "381/381 [==============================] - 0s 57us/sample - loss: 0.1971 - accuracy: 0.9501 - val_loss: 0.2059 - val_accuracy: 0.9468\n",
            "Epoch 26/100\n",
            "381/381 [==============================] - 0s 62us/sample - loss: 0.1924 - accuracy: 0.9501 - val_loss: 0.2014 - val_accuracy: 0.9521\n",
            "Epoch 27/100\n",
            "381/381 [==============================] - 0s 57us/sample - loss: 0.1882 - accuracy: 0.9554 - val_loss: 0.1969 - val_accuracy: 0.9521\n",
            "Epoch 28/100\n",
            "381/381 [==============================] - 0s 57us/sample - loss: 0.1840 - accuracy: 0.9554 - val_loss: 0.1926 - val_accuracy: 0.9521\n",
            "Epoch 29/100\n",
            "381/381 [==============================] - 0s 71us/sample - loss: 0.1801 - accuracy: 0.9554 - val_loss: 0.1887 - val_accuracy: 0.9521\n",
            "Epoch 30/100\n",
            "381/381 [==============================] - 0s 62us/sample - loss: 0.1763 - accuracy: 0.9606 - val_loss: 0.1849 - val_accuracy: 0.9574\n",
            "Epoch 31/100\n",
            "381/381 [==============================] - 0s 72us/sample - loss: 0.1728 - accuracy: 0.9606 - val_loss: 0.1813 - val_accuracy: 0.9574\n",
            "Epoch 32/100\n",
            "381/381 [==============================] - 0s 64us/sample - loss: 0.1694 - accuracy: 0.9633 - val_loss: 0.1778 - val_accuracy: 0.9574\n",
            "Epoch 33/100\n",
            "381/381 [==============================] - 0s 68us/sample - loss: 0.1661 - accuracy: 0.9633 - val_loss: 0.1744 - val_accuracy: 0.9574\n",
            "Epoch 34/100\n",
            "381/381 [==============================] - 0s 67us/sample - loss: 0.1633 - accuracy: 0.9633 - val_loss: 0.1711 - val_accuracy: 0.9574\n",
            "Epoch 35/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.1602 - accuracy: 0.9633 - val_loss: 0.1680 - val_accuracy: 0.9574\n",
            "Epoch 36/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.1574 - accuracy: 0.9633 - val_loss: 0.1651 - val_accuracy: 0.9574\n",
            "Epoch 37/100\n",
            "381/381 [==============================] - 0s 67us/sample - loss: 0.1547 - accuracy: 0.9633 - val_loss: 0.1624 - val_accuracy: 0.9574\n",
            "Epoch 38/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.1523 - accuracy: 0.9633 - val_loss: 0.1596 - val_accuracy: 0.9574\n",
            "Epoch 39/100\n",
            "381/381 [==============================] - 0s 56us/sample - loss: 0.1498 - accuracy: 0.9633 - val_loss: 0.1570 - val_accuracy: 0.9574\n",
            "Epoch 40/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.1474 - accuracy: 0.9633 - val_loss: 0.1546 - val_accuracy: 0.9574\n",
            "Epoch 41/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.1452 - accuracy: 0.9633 - val_loss: 0.1522 - val_accuracy: 0.9628\n",
            "Epoch 42/100\n",
            "381/381 [==============================] - 0s 70us/sample - loss: 0.1432 - accuracy: 0.9633 - val_loss: 0.1498 - val_accuracy: 0.9628\n",
            "Epoch 43/100\n",
            "381/381 [==============================] - 0s 60us/sample - loss: 0.1411 - accuracy: 0.9633 - val_loss: 0.1475 - val_accuracy: 0.9628\n",
            "Epoch 44/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.1391 - accuracy: 0.9633 - val_loss: 0.1454 - val_accuracy: 0.9628\n",
            "Epoch 45/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.1373 - accuracy: 0.9633 - val_loss: 0.1433 - val_accuracy: 0.9628\n",
            "Epoch 46/100\n",
            "381/381 [==============================] - 0s 64us/sample - loss: 0.1355 - accuracy: 0.9633 - val_loss: 0.1414 - val_accuracy: 0.9628\n",
            "Epoch 47/100\n",
            "381/381 [==============================] - 0s 60us/sample - loss: 0.1338 - accuracy: 0.9633 - val_loss: 0.1394 - val_accuracy: 0.9628\n",
            "Epoch 48/100\n",
            "381/381 [==============================] - 0s 60us/sample - loss: 0.1321 - accuracy: 0.9659 - val_loss: 0.1376 - val_accuracy: 0.9628\n",
            "Epoch 49/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.1305 - accuracy: 0.9659 - val_loss: 0.1358 - val_accuracy: 0.9628\n",
            "Epoch 50/100\n",
            "381/381 [==============================] - 0s 68us/sample - loss: 0.1291 - accuracy: 0.9659 - val_loss: 0.1340 - val_accuracy: 0.9628\n",
            "Epoch 51/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.1275 - accuracy: 0.9659 - val_loss: 0.1324 - val_accuracy: 0.9628\n",
            "Epoch 52/100\n",
            "381/381 [==============================] - 0s 62us/sample - loss: 0.1261 - accuracy: 0.9685 - val_loss: 0.1308 - val_accuracy: 0.9628\n",
            "Epoch 53/100\n",
            "381/381 [==============================] - 0s 63us/sample - loss: 0.1248 - accuracy: 0.9685 - val_loss: 0.1292 - val_accuracy: 0.9628\n",
            "Epoch 54/100\n",
            "381/381 [==============================] - 0s 65us/sample - loss: 0.1234 - accuracy: 0.9711 - val_loss: 0.1276 - val_accuracy: 0.9628\n",
            "Epoch 55/100\n",
            "381/381 [==============================] - 0s 63us/sample - loss: 0.1222 - accuracy: 0.9711 - val_loss: 0.1262 - val_accuracy: 0.9628\n",
            "Epoch 56/100\n",
            "381/381 [==============================] - 0s 68us/sample - loss: 0.1209 - accuracy: 0.9711 - val_loss: 0.1248 - val_accuracy: 0.9681\n",
            "Epoch 57/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.1197 - accuracy: 0.9738 - val_loss: 0.1235 - val_accuracy: 0.9681\n",
            "Epoch 58/100\n",
            "381/381 [==============================] - 0s 63us/sample - loss: 0.1187 - accuracy: 0.9738 - val_loss: 0.1221 - val_accuracy: 0.9681\n",
            "Epoch 59/100\n",
            "381/381 [==============================] - 0s 53us/sample - loss: 0.1176 - accuracy: 0.9738 - val_loss: 0.1210 - val_accuracy: 0.9681\n",
            "Epoch 60/100\n",
            "381/381 [==============================] - 0s 55us/sample - loss: 0.1165 - accuracy: 0.9738 - val_loss: 0.1197 - val_accuracy: 0.9681\n",
            "Epoch 61/100\n",
            "381/381 [==============================] - 0s 57us/sample - loss: 0.1154 - accuracy: 0.9738 - val_loss: 0.1184 - val_accuracy: 0.9681\n",
            "Epoch 62/100\n",
            "381/381 [==============================] - 0s 69us/sample - loss: 0.1145 - accuracy: 0.9738 - val_loss: 0.1172 - val_accuracy: 0.9681\n",
            "Epoch 63/100\n",
            "381/381 [==============================] - 0s 66us/sample - loss: 0.1134 - accuracy: 0.9738 - val_loss: 0.1161 - val_accuracy: 0.9681\n",
            "Epoch 64/100\n",
            "381/381 [==============================] - 0s 92us/sample - loss: 0.1125 - accuracy: 0.9738 - val_loss: 0.1150 - val_accuracy: 0.9681\n",
            "Epoch 65/100\n",
            "381/381 [==============================] - 0s 64us/sample - loss: 0.1117 - accuracy: 0.9738 - val_loss: 0.1140 - val_accuracy: 0.9681\n",
            "Epoch 66/100\n",
            "381/381 [==============================] - 0s 57us/sample - loss: 0.1108 - accuracy: 0.9738 - val_loss: 0.1130 - val_accuracy: 0.9681\n",
            "Epoch 67/100\n",
            "381/381 [==============================] - 0s 62us/sample - loss: 0.1099 - accuracy: 0.9711 - val_loss: 0.1120 - val_accuracy: 0.9681\n",
            "Epoch 68/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.1091 - accuracy: 0.9738 - val_loss: 0.1110 - val_accuracy: 0.9681\n",
            "Epoch 69/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.1083 - accuracy: 0.9738 - val_loss: 0.1101 - val_accuracy: 0.9681\n",
            "Epoch 70/100\n",
            "381/381 [==============================] - 0s 60us/sample - loss: 0.1075 - accuracy: 0.9738 - val_loss: 0.1091 - val_accuracy: 0.9681\n",
            "Epoch 71/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.1067 - accuracy: 0.9738 - val_loss: 0.1081 - val_accuracy: 0.9681\n",
            "Epoch 72/100\n",
            "381/381 [==============================] - 0s 62us/sample - loss: 0.1059 - accuracy: 0.9738 - val_loss: 0.1073 - val_accuracy: 0.9681\n",
            "Epoch 73/100\n",
            "381/381 [==============================] - 0s 66us/sample - loss: 0.1052 - accuracy: 0.9738 - val_loss: 0.1064 - val_accuracy: 0.9681\n",
            "Epoch 74/100\n",
            "381/381 [==============================] - 0s 60us/sample - loss: 0.1046 - accuracy: 0.9738 - val_loss: 0.1055 - val_accuracy: 0.9681\n",
            "Epoch 75/100\n",
            "381/381 [==============================] - 0s 66us/sample - loss: 0.1039 - accuracy: 0.9738 - val_loss: 0.1047 - val_accuracy: 0.9681\n",
            "Epoch 76/100\n",
            "381/381 [==============================] - 0s 69us/sample - loss: 0.1032 - accuracy: 0.9738 - val_loss: 0.1039 - val_accuracy: 0.9681\n",
            "Epoch 77/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.1026 - accuracy: 0.9764 - val_loss: 0.1031 - val_accuracy: 0.9681\n",
            "Epoch 78/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.1019 - accuracy: 0.9764 - val_loss: 0.1024 - val_accuracy: 0.9681\n",
            "Epoch 79/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.1013 - accuracy: 0.9764 - val_loss: 0.1017 - val_accuracy: 0.9681\n",
            "Epoch 80/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.1007 - accuracy: 0.9764 - val_loss: 0.1009 - val_accuracy: 0.9681\n",
            "Epoch 81/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.1001 - accuracy: 0.9764 - val_loss: 0.1002 - val_accuracy: 0.9734\n",
            "Epoch 82/100\n",
            "381/381 [==============================] - 0s 60us/sample - loss: 0.0996 - accuracy: 0.9764 - val_loss: 0.0997 - val_accuracy: 0.9734\n",
            "Epoch 83/100\n",
            "381/381 [==============================] - 0s 63us/sample - loss: 0.0990 - accuracy: 0.9764 - val_loss: 0.0989 - val_accuracy: 0.9734\n",
            "Epoch 84/100\n",
            "381/381 [==============================] - 0s 63us/sample - loss: 0.0984 - accuracy: 0.9764 - val_loss: 0.0982 - val_accuracy: 0.9734\n",
            "Epoch 85/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.0979 - accuracy: 0.9764 - val_loss: 0.0976 - val_accuracy: 0.9734\n",
            "Epoch 86/100\n",
            "381/381 [==============================] - 0s 69us/sample - loss: 0.0974 - accuracy: 0.9764 - val_loss: 0.0970 - val_accuracy: 0.9734\n",
            "Epoch 87/100\n",
            "381/381 [==============================] - 0s 74us/sample - loss: 0.0969 - accuracy: 0.9764 - val_loss: 0.0964 - val_accuracy: 0.9734\n",
            "Epoch 88/100\n",
            "381/381 [==============================] - 0s 67us/sample - loss: 0.0964 - accuracy: 0.9764 - val_loss: 0.0957 - val_accuracy: 0.9734\n",
            "Epoch 89/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.0959 - accuracy: 0.9764 - val_loss: 0.0952 - val_accuracy: 0.9734\n",
            "Epoch 90/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.0955 - accuracy: 0.9764 - val_loss: 0.0947 - val_accuracy: 0.9734\n",
            "Epoch 91/100\n",
            "381/381 [==============================] - 0s 56us/sample - loss: 0.0949 - accuracy: 0.9764 - val_loss: 0.0940 - val_accuracy: 0.9734\n",
            "Epoch 92/100\n",
            "381/381 [==============================] - 0s 59us/sample - loss: 0.0945 - accuracy: 0.9764 - val_loss: 0.0935 - val_accuracy: 0.9734\n",
            "Epoch 93/100\n",
            "381/381 [==============================] - 0s 56us/sample - loss: 0.0940 - accuracy: 0.9764 - val_loss: 0.0930 - val_accuracy: 0.9734\n",
            "Epoch 94/100\n",
            "381/381 [==============================] - 0s 58us/sample - loss: 0.0937 - accuracy: 0.9764 - val_loss: 0.0925 - val_accuracy: 0.9734\n",
            "Epoch 95/100\n",
            "381/381 [==============================] - 0s 60us/sample - loss: 0.0931 - accuracy: 0.9764 - val_loss: 0.0919 - val_accuracy: 0.9734\n",
            "Epoch 96/100\n",
            "381/381 [==============================] - 0s 70us/sample - loss: 0.0927 - accuracy: 0.9764 - val_loss: 0.0915 - val_accuracy: 0.9734\n",
            "Epoch 97/100\n",
            "381/381 [==============================] - 0s 63us/sample - loss: 0.0923 - accuracy: 0.9764 - val_loss: 0.0909 - val_accuracy: 0.9734\n",
            "Epoch 98/100\n",
            "381/381 [==============================] - 0s 70us/sample - loss: 0.0919 - accuracy: 0.9764 - val_loss: 0.0904 - val_accuracy: 0.9734\n",
            "Epoch 99/100\n",
            "381/381 [==============================] - 0s 65us/sample - loss: 0.0915 - accuracy: 0.9764 - val_loss: 0.0899 - val_accuracy: 0.9734\n",
            "Epoch 100/100\n",
            "381/381 [==============================] - 0s 61us/sample - loss: 0.0912 - accuracy: 0.9764 - val_loss: 0.0895 - val_accuracy: 0.9734\n",
            "381/381 [==============================] - 0s 68us/sample - loss: 0.0909 - accuracy: 0.9764\n",
            "Train Score: [0.09086953971798964, 0.97637796]\n",
            "188/188 [==============================] - 0s 45us/sample - loss: 0.0895 - accuracy: 0.9734\n",
            "Test Score: [0.08948123550161402, 0.9734042]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN8oglNXC_Wy",
        "colab_type": "code",
        "outputId": "7b4c1374-6e5e-4894-cfc6-557c7cfca52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# Plot what's Returned by model.fit()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['loss'], label=\"Loss\")\n",
        "plt.plot(r.history['val_loss'], label=\"Val_Loss\")\n",
        "plt.title(\"Loss Plot\")\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRD1fDQgDXCC",
        "colab_type": "code",
        "outputId": "c32f87c8-4351-4344-fd70-3af8cd1df22d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# Plot the Accuracy\n",
        "plt.plot(r.history['accuracy'], label=\"Accuracy\")\n",
        "plt.plot(r.history['val_accuracy'], label=\"Val_Accuracy\")\n",
        "plt.title(\"Accuracy Plot\")\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+/9IC97OzWjRzQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m54cayfnxf_p",
        "colab_type": "text"
      },
      "source": [
        "**Making Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfzUIh50xkny",
        "colab_type": "code",
        "outputId": "f216393f-077b-4977-81ce-6e64a9a98918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Make Predictions\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred) # Their Probablities, Outputs of Sigmoid Function"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.38941455e-01]\n",
            " [2.72741914e-03]\n",
            " [3.95572186e-02]\n",
            " [9.80416417e-01]\n",
            " [9.96421695e-01]\n",
            " [2.38418579e-07]\n",
            " [7.21216202e-06]\n",
            " [1.44410312e-01]\n",
            " [5.61171114e-01]\n",
            " [9.91328716e-01]\n",
            " [8.76091003e-01]\n",
            " [1.31120503e-01]\n",
            " [9.49967146e-01]\n",
            " [1.16317213e-01]\n",
            " [9.85732913e-01]\n",
            " [2.34213471e-03]\n",
            " [9.84621763e-01]\n",
            " [9.99141335e-01]\n",
            " [9.99842107e-01]\n",
            " [2.63482332e-04]\n",
            " [8.28539491e-01]\n",
            " [9.44780767e-01]\n",
            " [5.48362732e-06]\n",
            " [9.98432994e-01]\n",
            " [9.87057209e-01]\n",
            " [9.85932291e-01]\n",
            " [9.83720183e-01]\n",
            " [9.71815348e-01]\n",
            " [9.72840488e-01]\n",
            " [5.57601452e-04]\n",
            " [9.84126985e-01]\n",
            " [9.96514082e-01]\n",
            " [9.94547486e-01]\n",
            " [9.64595437e-01]\n",
            " [9.96539414e-01]\n",
            " [9.87420917e-01]\n",
            " [2.45417297e-01]\n",
            " [9.96303856e-01]\n",
            " [5.36909699e-03]\n",
            " [8.62635970e-01]\n",
            " [9.97031212e-01]\n",
            " [2.05549598e-02]\n",
            " [9.74925339e-01]\n",
            " [9.87488627e-01]\n",
            " [9.71595466e-01]\n",
            " [9.00433779e-01]\n",
            " [9.94728327e-01]\n",
            " [9.95833635e-01]\n",
            " [8.87150824e-01]\n",
            " [9.86477852e-01]\n",
            " [6.94948435e-03]\n",
            " [3.72529030e-05]\n",
            " [5.30468047e-01]\n",
            " [9.30728018e-01]\n",
            " [9.97247636e-01]\n",
            " [9.70982075e-01]\n",
            " [9.96093035e-01]\n",
            " [1.78813934e-07]\n",
            " [2.98844874e-01]\n",
            " [9.97025013e-01]\n",
            " [9.56211150e-01]\n",
            " [1.86771154e-04]\n",
            " [1.38282776e-05]\n",
            " [9.08287644e-01]\n",
            " [9.92434502e-01]\n",
            " [8.18646073e-01]\n",
            " [1.06301904e-03]\n",
            " [1.66893005e-06]\n",
            " [9.85178411e-01]\n",
            " [8.70352507e-01]\n",
            " [3.65447104e-02]\n",
            " [3.05637121e-02]\n",
            " [9.80083108e-01]\n",
            " [2.54650712e-02]\n",
            " [9.99192357e-01]\n",
            " [9.32718635e-01]\n",
            " [9.35856521e-01]\n",
            " [5.07397652e-01]\n",
            " [9.98852968e-01]\n",
            " [9.34856832e-01]\n",
            " [3.55309546e-02]\n",
            " [9.98409152e-01]\n",
            " [3.22043151e-01]\n",
            " [1.42753124e-05]\n",
            " [4.35074568e-02]\n",
            " [1.33241713e-02]\n",
            " [1.85742974e-03]\n",
            " [4.03699279e-03]\n",
            " [9.92554426e-01]\n",
            " [9.60808516e-01]\n",
            " [9.59826231e-01]\n",
            " [5.58856845e-01]\n",
            " [8.84517431e-01]\n",
            " [9.91650701e-01]\n",
            " [9.93054867e-01]\n",
            " [9.97630835e-01]\n",
            " [2.17288733e-04]\n",
            " [3.45021486e-04]\n",
            " [9.98260498e-01]\n",
            " [8.72036815e-03]\n",
            " [4.36648428e-02]\n",
            " [9.99785423e-01]\n",
            " [1.79213285e-03]\n",
            " [1.43125057e-02]\n",
            " [9.76458549e-01]\n",
            " [9.31509733e-01]\n",
            " [9.55346465e-01]\n",
            " [4.50015068e-06]\n",
            " [7.96664238e-01]\n",
            " [8.78837705e-01]\n",
            " [5.24104536e-02]\n",
            " [9.88199055e-01]\n",
            " [4.28205192e-01]\n",
            " [2.38418579e-07]\n",
            " [3.28276098e-01]\n",
            " [4.20212746e-06]\n",
            " [9.99708772e-01]\n",
            " [9.11579370e-01]\n",
            " [9.98973370e-01]\n",
            " [2.24873424e-03]\n",
            " [9.64007139e-01]\n",
            " [9.92888451e-01]\n",
            " [9.75321889e-01]\n",
            " [2.93126702e-03]\n",
            " [8.89983773e-01]\n",
            " [1.82509422e-04]\n",
            " [1.35444105e-02]\n",
            " [9.94726896e-01]\n",
            " [9.84768271e-01]\n",
            " [2.43782997e-04]\n",
            " [1.85072422e-05]\n",
            " [2.01165676e-04]\n",
            " [9.70476866e-01]\n",
            " [9.86820459e-01]\n",
            " [9.32486534e-01]\n",
            " [3.41478586e-02]\n",
            " [6.59332752e-01]\n",
            " [9.77902234e-01]\n",
            " [6.29623413e-01]\n",
            " [1.78372264e-02]\n",
            " [9.79208708e-01]\n",
            " [3.42726707e-05]\n",
            " [9.98808861e-01]\n",
            " [9.98812973e-01]\n",
            " [5.11045158e-02]\n",
            " [9.84801531e-01]\n",
            " [5.10841608e-04]\n",
            " [5.91129065e-04]\n",
            " [3.80596995e-01]\n",
            " [9.95822906e-01]\n",
            " [2.49587536e-01]\n",
            " [9.98238444e-01]\n",
            " [9.99608696e-01]\n",
            " [9.03495610e-01]\n",
            " [9.89566803e-01]\n",
            " [0.00000000e+00]\n",
            " [2.06959248e-03]\n",
            " [9.99570489e-01]\n",
            " [9.50167418e-01]\n",
            " [9.99287605e-01]\n",
            " [9.99923825e-01]\n",
            " [9.94051039e-01]\n",
            " [9.97835636e-01]\n",
            " [9.80899692e-01]\n",
            " [2.34930366e-01]\n",
            " [9.89198267e-01]\n",
            " [9.90928650e-01]\n",
            " [7.16663837e-01]\n",
            " [9.96319056e-01]\n",
            " [6.33195341e-02]\n",
            " [8.68153095e-01]\n",
            " [9.84066010e-01]\n",
            " [9.86598015e-01]\n",
            " [7.37115860e-01]\n",
            " [9.84237194e-01]\n",
            " [8.85484278e-01]\n",
            " [2.39392191e-01]\n",
            " [8.72271061e-01]\n",
            " [9.82779086e-01]\n",
            " [9.24523234e-01]\n",
            " [8.49235654e-01]\n",
            " [9.08971310e-01]\n",
            " [9.94688034e-01]\n",
            " [1.11094922e-01]\n",
            " [8.98022018e-03]\n",
            " [1.71438739e-01]\n",
            " [3.28855246e-01]\n",
            " [9.05951023e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RNscxlFx0gN",
        "colab_type": "code",
        "outputId": "63528113-34b3-4603-f636-5c638a06ad49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Actual Prediction. It Must be Flattened, as Targets are of size (N,) and predictions are of size (N,1)\n",
        "import numpy as np\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.\n",
            " 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De_fIffSyK-G",
        "colab_type": "code",
        "outputId": "2e58da53-e424-4e1b-b804-9926f700b7f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Calculating Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"The Evaluation of Model is: \", model.evaluate(X_test, y_test))\n",
        "print(\"The Accuracy of the model is: \", accuracy_score(y_pred, y_test)*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "188/188 [==============================] - 0s 71us/sample - loss: 0.0895 - accuracy: 0.9734\n",
            "The Evaluation of Model is:  [0.08948123550161402, 0.9734042]\n",
            "The Accuracy of the model is:  97.3404255319149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-rRw6Fk06ma",
        "colab_type": "text"
      },
      "source": [
        "**Saving the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BECgbLOv0-zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving as h5 file\n",
        "\n",
        "model.save('0_linear_Classification.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve06CU3m1H2k",
        "colab_type": "code",
        "outputId": "125d1c52-ac58-4c9b-d7ad-a934bab110ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Check the existence of model file\n",
        "!ls -lh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 24K\n",
            "-rw-r--r-- 1 root root  19K Jan 16 14:53 0_linear_Classification.h5\n",
            "drwxr-xr-x 1 root root 4.0K Jan 13 16:38 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npISiDuq1MbH",
        "colab_type": "code",
        "outputId": "1c114adb-2905-4834-e1d0-53f083b38881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Loading the Model\n",
        "\n",
        "model = tf.keras.models.load_model('0_linear_Classification.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-df48071e2a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0_linear_Classification.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    135\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    136\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    669\u001b[0m                      \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                      \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                      ' layers.')\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 1 layers into a model with 0 layers."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMejG32P1XyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to load the model by changing the Model creation by removing Explicit Input function\n",
        "\n",
        "# Loading the Model\n",
        "\n",
        "model = tf.keras.models.load_model('0_linear_Classification.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRlrv8122J8B",
        "colab_type": "code",
        "outputId": "4045f974-9015-455c-c428-ab95ad08efaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Verifying the Loaded Weights\n",
        "print(model.layers)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.layers.core.Dense object at 0x7fc8f55e42e8>]\n",
            "188/188 [==============================] - 0s 171us/sample - loss: 0.0895 - accuracy: 0.9734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08948123550161402, 0.9734042]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX7UY0ff2TDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}